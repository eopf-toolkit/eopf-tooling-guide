---
title: "The Benefits of EOPF Zarr over SAFE"
format:
  md:
    df-print: tibble
execute:
  cache: true
---

# Table of Contents

# TODO

# Introduction

This tutorial will explore the benefits of EOPF Zarr over the prior format, SAFE (Standard Archive Format for Europe). It is the third in a series of working with EOPF Zarr data in R, and follows the [first tutorial](/eopf_stac_access.md), which goes into more detail on accessing and searching within the STAC catalog, and the [second](/eopf_zarr.md), which shows how to access and analyse Zarr data from the catalog.

# Prerequisites

An R environment is required to follow this tutorial, with R version >= 4.1.0. We recommend using either [RStudio](https://posit.co/download/rstudio-desktop/) or [Positron](https://posit.co/products/ide/positron/) (or a cloud computing environment) and making use of [RStudio projects](https://support.posit.co/hc/en-us/articles/200526207-Using-RStudio-Projects) for a self-contained coding environment.

## Dependencies

We will use the following packages in this tutorial: [`rstac`](https://brazil-data-cube.github.io/rstac/) (for accessing the STAC catalog), [`tidyverse`](https://tidyverse.tidyverse.org/) (for data manipulation), [`stars`](https://r-spatial.github.io/stars/)) (for working with spatiotemporal data), [`terra`](https://rspatial.github.io/terra/index.html) (for working with spatial data in raster format), [`httr2`](https://httr2.r-lib.org/) (for working with APIs), [`xml2`](https://xml2.r-lib.org) (for accessing metadata from SAFE files), [`fs`](https://fs.r-lib.org/) (for accessing file locations and sizes), and [`lobstr`](https://lobstr.r-lib.org) (for calculating the size of objects within R). You can install them directly from CRAN. Note that `xml2` is a part of `tidyverse`, so it does not need ot be installed separately, but it will be loaded separately.

```{r install-rstac}
#| eval: false
install.packages("rstac")
install.packages("tidyverse")
install.packages("stars")
install.packages("terra")
install.packages("httr2")
install.packages("fs")
```

We will also use the `Rarr` package to read Zarr data. It must be installed from Bioconductor, so first install the `BiocManager` package:

```{r install-BiocManager}
#| eval: false
install.packages("BiocManager")
```

Then, use this package to install `Rarr`:

```{r install-rarr}
#| eval: false
BiocManager::install("Rarr")
```

Finally, load the packages into your environment:

```{r load, message=FALSE}
#| cache: false
library(rstac)
library(tidyverse)
library(stars)
library(terra)
library(xml2)
library(httr2)
library(fs)
library(lobstr)
library(Rarr)
```

## Fixes to the `Rarr` package

We will use functions from the `Rarr` package to read and analyse Zarr data. Unfortunately, there is currently a bug in this package, causing it to parse the EOPF Sample Service data URLs incorrectly -- it has been fixed and will be updated in the next release of `Rarr`. In the meantime, we will write our own version of this URL parsing function and use it instead of the one in `Rarr`.

```{r overwrite-url-parsing}
#| cache: false
.url_parse_other <- function(url) {
  parsed_url <- httr::parse_url(url)
  bucket <- gsub(
    x = parsed_url$path, pattern = "^/?([[a-z0-9\\:\\.-]*)/.*",
    replacement = "\\1", ignore.case = TRUE
  )
  object <- gsub(
    x = parsed_url$path, pattern = "^/?([a-z0-9\\:\\.-]*)/(.*)",
    replacement = "\\2", ignore.case = TRUE
  )
  hostname <- paste0(parsed_url$scheme, "://", parsed_url$hostname)

  if (!is.null(parsed_url$port)) {
    hostname <- paste0(hostname, ":", parsed_url$port)
  }

  res <- list(
    bucket = bucket,
    object = object,
    region = "auto",
    hostname = hostname
  )
  return(res)
}

assignInNamespace(".url_parse_other", .url_parse_other, ns = "Rarr")
```

This function overwrites the existing one in `Rarr`, and allows us to continue with the analysis.

If you try to run some of the examples below and receive a timeout error, please ensure that you have run the above code block.

# The Benefits of EOPF Zarr over SAFE

Prior to the introduction of EOPF's Zarr, the ESA's Copernicus data was published and distributed using the [Standard Archive Format for Europe (SAFE)](https://earth.esa.int/eogateway/activities/safe-the-standard-archive-format-for-europe). Sentinel scenes were downloaded as zip archives, containing several files as well as an XML manifest. In order to access any scene data, the entire zip archive had to be downloaded, which could be quite inefficient.

Zarr is optimised for efficient data retrieval---arrays are segmented into one or more chunks, and a single Sentinel scene could potentially be across several chunks. A data consumer can choose to download only the chunks required for their use case, rather than the entire zip archive. There is no need to download all data before processing it, and data can be **lazy-loaded** so that it is only downloaded when required. The [Data Retrieval and Efficiency](TODO) section shows how this is more efficient in terms of both network bandwidth and compute resources.

TODO, explain that we will first show Zarr and then show SAFE?

## Zarr example

The following example shows how to access the 60-metre resolution quicklook of a Sentinel-2 mission (TODO -> what is this exactly)? It is explored in more detail in the [previous tutorial](/eopf_zarr.md), which we recommend reviewing first for full context. For comparison to an example using SAFE data, we set up `zarr_start` and `zarr_end` to time the data retrieval and visualisation process.

```{r zarr-ex}
zarr_start <- Sys.time()

s2_l2a_item <- stac("https://stac.core.eopf.eodc.eu/") |>
  collections(collection_id = "sentinel-2-l2a") |>
  items(feature_id = "S2B_MSIL2A_20250530T101559_N0511_R065_T32TPT_20250530T130924") |>
  get_request()

s2_l2a_product <- s2_l2a_item |>
  assets_select(asset_names = "product")

s2_l2a_product_url <- s2_l2a_product |>
  assets_url()

zarr_store <- s2_l2a_product_url |>
  zarr_overview(as_data_frame = TRUE) |>
  mutate(array = str_remove(path, s2_l2a_product_url)) |>
  relocate(array, .before = path)

r60m_tci <- zarr_store |>
  filter(array == "/quality/l2a_quicklook/r60m/tci") |>
  pull(path) |>
  read_zarr_array()

r60m_tci <- r60m_tci |>
  aperm(c(2, 3, 1)) |>
  rast()

r60m_tci |>
  plotRGB()

zarr_end <- Sys.time()
```

We can see how long this whole process took:

```{r zarr-time}
zarr_time <- zarr_end - zarr_start

zarr_time
```

And can look at the size of the `r60m_tci` object using `lobstr`'s `obj_size()`

```{r zarr-size-show}
#| eval: false
obj_size(r60m_tci)
```

```{r zarr-size-hide}
#| echo: false
zarr_size <- r60m_tci |>
  obj_size()

zarr_size
```

## Comparable SAFE example

The following example accesses the same 60-metre quicklook image as the example above, using SAFE instead of EOPF Zarr. We will show how using Zarr takes less time, memory, and downloads less data.

This example also requires authentication to the SAFE STAC API. You need a [Copernicus Dataspace](https://dataspace.copernicus.eu/)
account, and to register an OAuth 2.0 client as described in [this article](https://documentation.dataspace.copernicus.eu/APIs/SentinelHub/Overview/Authentication.html). The resulting Client Credentials should be stored in the environment variables `CDSE_ID` and `CDSE_SECRET` (using e.g. `usethis::edit_r_environ()` to set these).

We then use this to generate a **token**:

```{r client-token}
token <- oauth_client("https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token",
  id = "sh-62112dad-7f8c-4e1f-abc1-16cf93519302",
  secret = "YrdqqqigqQ7630Ql6Ef6gxjU683j9M06",
) |>
  oauth_flow_client_credentials()

token
```

which will be used for accessing SAFE data. The `token` object contains the token itself and, as you can see, when it expires: 10 minutes after generation. 

To access the SAFE data, we first get the STAC item from the Sentinel-2 collection. Its ID is the same as in the EOPF Sample Service STAC catalog example, with the suffix `.SAFE`. We'll also set up timing how long this process takes in `safe_start`.

```{r safe-item}
safe_start <- Sys.time()

safe_id <- "S2B_MSIL2A_20250530T101559_N0511_R065_T32TPT_20250530T130924.SAFE"

safe_item <- stac("https://catalogue.dataspace.copernicus.eu/stac/") |>
  collections(collection_id = "SENTINEL-2") |>
  items(feature_id = safe_id) |>
  get_request()

safe_item
```

The relevant asset is "PRODUCT":

```{r safe-asset}
safe_item |>
  items_assets()
```

We can select its URL for accessing the data:

```{r safe-product-url}
safe_url <- safe_item |>
  assets_select(asset_names = "PRODUCT") |>
  assets_url()

safe_url
```

However, this URL actually redirects if we try to download the data, and the token is not properly passed. We must then first access the redirected URL. The following code sets up the API request via `httr2`'s `request()`, sets an option not to follow the redirect (so we can access the redirect URL manually), performs the request (via `req_perform()`), then accesses the new location from the header:

```{r safe-product-redirect}
safe_redirect_url <- request(safe_url) |>
  req_options(followlocation = FALSE) |>
  req_perform() |>
  resp_header("location")

safe_redirect_url
```

The difference in the URL is that it is prefixed with `download` instead of `catalogue`. Now, we can use this new URL to actually get the data. Again, we set up the request, this time adding in the token as a Bearer token so that we are authenticated and have permission to access the data. There is also error handling, which is informative in case the token has expired; in which case, the above OAuth token generation code should be rerun. Finally, we perform the request and safe it to a ZIP file, stored in `safe_zip`.

```{r safe-get-hide}
#| echo: false
#| cache: false
# in non-temp dir for interactive development
safe_dir <- here::here("scratch", "safe")
safe_zip <- paste0(safe_dir, "/", safe_id, ".zip")

if (!file_exists(safe_zip)) {
  request(safe_redirect_url) |>
    req_auth_bearer_token(token$access_token) |>
    req_error(body = \(x) resp_body_json(x)[["message"]]) |>
    req_perform(path = safe_zip)
}
```

```{r safe-get-show}
#| eval: false
safe_dir <- tempdir()
safe_zip <- paste0(safe_dir, "/", safe_id, ".zip")

request(safe_redirect_url) |>
  req_auth_bearer_token(token$access_token) |>
  req_error(body = \(x) resp_body_json(x)[["message"]]) |>
  req_perform(path = safe_zip)
```

We need to unzip the file and find the manifest file, which contains information on where different data sets are.

```{r safe-unzip-find}
# TODO, sort out path etc
safe_unzip_dir <- paste0(safe_dir, "/", safe_id) # TODO
unzip(safe_zip, exdir = safe_dir)

safe_files_dir <- paste0(safe_unzip_dir, "/", safe_id)

safe_files <- tibble(path = dir_ls(safe_files_dir)) |>
  mutate(file = basename(path)) |>
  relocate(file, .before = path)

safe_files

manifest_location <- safe_files |>
  filter(file == "manifest.safe") |>
  pull(path)

manifest_location
```

We then read in the manifest file, and find the location of the 60-metre resolution data.

```{r safe-manifest}
manifest <- read_xml(manifest_location)

safe_60m_quicklook_location <- manifest |>
  xml_find_first(".//dataObject[@ID='IMG_DATA_Band_TCI_60m_Tile1_Data']/byteStream/fileLocation") |>
  xml_attr("href")

safe_60m_quicklook_location
```

Which we can then read in and visualize:

```{r safe-plot}
safe_60m_quicklook_location <- paste0(safe_files_dir, safe_60m_quicklook_location %>% str_remove("\\."))
  
r60m_tci_safe <- stars::read_stars(safe_60m_quicklook_location) |>
  stars::st_rgb()

r60m_tci_safe |>
  plot()

safe_end <- Sys.time()
```

## Comparing EOPF Zarr versus SAFE

To contrast with the Zarr example, we'll look at how long the processes took, how large the objects are, and how much data was saved to disk.

First, to compare the time:

```{r time-comparison}
zarr_time <- zarr_end - zarr_start

zarr_time

safe_time <- safe_end - safe_start

safe_time

safe_time - zarr_time
```

And the size of the objects in R:

```{r object-size-comparison}
obj_size(r60m_tci)

obj_size(r60m_tci_safe)

obj_size(r60m_tci_safe) - obj_size(r60m_tci)
```

Note also that the SAFE example requires saving the entire archive to disk, while nothing is saved to disk in the Zarr example. The size of the full archive is:

```{r safe-disk-size-show}
#| eval: false
file_size(safe_zip)
```

```{r safe-disk-size-hide}
#| echo: false
safe_zip_size <- file_size(safe_zip)
safe_zip_size
```

while the size of the manifest file, and the 60-metre resolution quicklook file are:

```{r safe-manifest-size-show}
#| eval: false
file_size(manifest_location)
```

```{r safe-manifest-size-hide}
#| echo: false
manifest_size <- file_size(manifest_location)

manifest_size
```

```{r safe-quicklook-size-show}
#| eval: false
file_size(safe_60m_quicklook_location)
```

```{r safe-quicklook-size-hide}
#| echo: false
quicklook_size <- file_size(safe_60m_quicklook_location)

total_used_size <- manifest_size + quicklook_size

total_used_percent <- paste0(round(as.numeric(total_used_size) / as.numeric(safe_zip_size) * 100, 2), "%")

quicklook_size
```


So, of the `r safe_zip_size` saved to disk, only `r total_used_size` was actually read in -- only `r total_used_percent`.

To summarise:

```{r summary-table}
#| echo: false
tribble(
  ~Format, ~`Time`, ~`Downloaded to disk`, ~`Download used`, ~`Object size`,
  "EOPF Zarr", zarr_time, "---", "---", zarr_size,
  "SAFE", safe_time, as.character(safe_zip_size), total_used_percent, obj_size(r60m_tci_safe)
)
```
